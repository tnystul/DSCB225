---
title: "DSCB Lecture 2"
output: html_notebook
---

Todd Nystul\
January 14, 2025

### Load libraries and load and summarize data

```{r}
# load libraries
library(tidyverse)
```

Make some untidy data and then make it tidy

runif() generates n random numbers in the specified range and as.integer() rounds them to the nearest integer
```{r}
# make untidy data
untidy <- data.frame(
  mouse = c(1:5),
  Day1 = c(as.integer(runif(n = 5, min = 10, max = 20))),
  Day2 = c(as.integer(runif(n = 5, min = 15, max = 25))),
  Day3 = c(as.integer(runif(n = 5, min = 20, max = 30)))
)

# make the data tidy
tidy <- pivot_longer(untidy, !mouse, names_to = "Day", values_to = "Count")
```

```{r}
# load data and summarize
data(iris)
summary(iris)

plot(x=iris$Sepal.Length, y=iris$Petal.Length, xlab = "Sepal Length", ylab = "Petal Length")
```

```{r}
pdf("../Results/SepalPetal.pdf")
plot(x=iris$Sepal.Length, y=iris$Petal.Length, xlab = "Sepal Length", ylab = "Petal Length")
dev.off()
```

```{r}
# use the plot() function to create a scatter plot showing the relationship between sepal length and sepal width
# refer to line 37 above if you need help but don't just copy/paste--type it in yourself!


```


```{r}
mean(iris$Sepal.Length)

# use median() and sd() to calculate the median and standard deviation of sepal length

```

```{r}
# generate a sample distribution of Sepal Width
hist(iris$Sepal.Width, xlab = "", main = "Sepal Width")
```

Does it look normally distributed? Generate a q-q plot to visualize another way

```{r}
# generate a q-q plot
qqnorm(iris$Sepal.Width)
qqline(iris$Sepal.Width)
```

Alternatively, perform a distribution test

```{r}
shapiro.test(iris$Sepal.Width)
```

A p-value *greater* 0.05 means that the test does not reject the null hypothesis (i.e. p > 0.05 means that the data do not deviate significantly from a normal distribution)

```{r}
# repeat to generate a q-q plot and perform a Shapiro Test for Sepal Length
# refer to lines 70, 71 and 77 above if you need help but do not copy/paste!


```

```{r}
# use filter(data, column == "...") to filter the data for the species virginica
virginica <- filter(iris, Species == "virginica")
head(virginica) # shows the first six rows of the dataframe
```

```{r}
# filter using two criteria, species virginica and Sepal.Length greater than 6, separating each criterion with a comma and store the result in a dataframe called "virginica6"


tail(virginica6)  # shows the last 6 rows of the dataframe
```

```{r}
# generate a sample distribution of Sepal Width in virginica

```

```{r}
# generate a q-q plot of sepal length in virginica

```

### Parse the data for further analysis

```{r}
# use select(data, column1, column2, ...) to select specified columns
Sepal <- select(iris, Sepal.Length, Sepal.Width)
# select all columns from Sepal.Length to Petal.Length using a : to separate the beginning and end of the range


head(Sepal, 3)
```

```{r}
# use the mutate() function to add a new column based on data in other columns
iris <- iris %>% mutate(RoundSepal = Sepal.Width > 0.5 * Sepal.Length) # %>% is used to chain steps together
```

```{r}
# summarize by species
SepalLengthSummary <- iris %>% 
  group_by(Species) %>% 
  summarize(
    SepalLength_mean = mean(Sepal.Length),
    SepalLength_sd = sd(Sepal.Length),
    SepalLength_se = sd(Sepal.Length)/sqrt(length(Sepal.Length))
    )

barplot(SepalLengthSummary$SepalLength_mean, names.arg = SepalLengthSummary$Species)
```

Note, standard error calculation (SepalLength_se) is just provided here to demonstrate how it is calculated. Since the iris dataset seems to be more of a descriptive dataset and doesn't include information about technical replicates, standard deviation is probably a more appropriate measure of variability than standard error in this case.

```{r}
# save data to your results folder
write.csv(SepalLengthSummary, "../Results/SepalLengthSummary.csv")
```

### **Hypothesis testing:**

First, are the data normally distributed?

```{r}
# test for normality
shapiro.test(virginica$Sepal.Width)

# use the filter() function in a pipe to filter the iris dataset for data about the setosa species and repeat the Shapiro test on this subset of the data


```

**Test 1**: Does the roundness of setosa sepals differ from the roundness of virginica sepals (as defined by the RoundSepal category)?

```{r}
# use the filter() function in a pipe to separate out the data for both virginica and setosa into a new dataframe called VergSeto.  Hint: the | character is used to mean "or"


# to perform chi-squared test
VirgSeto$Species <- droplevels(VirgSeto$Species)  # this is to correct for an odd quirk that doesn't come up often
table(VirgSeto$Species, VirgSeto$RoundSepal)  # this line just shows you what contingency table looks like
chisq.test(table(VirgSeto$Species, VirgSeto$RoundSepal)) # here, we actually run the test
```

**Test 2**: Does sepal width vary between virginica and setosa? 

Null hypothesis: The mean sepal widths of the two species are not different from each other 

Alternative hypothesis: The mean sepal widths of the two species are different from each other

```{r}
# perform t-test
t.test(Sepal.Width ~ Species, data = VirgSeto) # read the ~ character as "as a function of"
```

The p-value is less than 0.05 so we would typically consider the difference between the means of these two populations to be statistically significant. Is it biologically significant? You would have to know more about the biology of these plants to make that determination

**Test 3**: How well are sepal width and sepal length correlated in virginica?

```{r}
cor.test(virginica$Sepal.Length, virginica$Sepal.Width)
```

Low p-value indicates that a linear model of these data is appropriate; modest r-squared value (cor) indicates that the correlation is mediocre. What does this look like on a graph?

```{r}
# generate a linear model of the data
Sepal_lm <- lm(Sepal.Length ~ Sepal.Width, data = virginica)
Sepal_lm
```

```{r}
plot(x=virginica$Sepal.Width, y=virginica$Sepal.Length)
abline(Sepal_lm)
```

```{r}
# Predict the sepal length based on sepal width (in reality, you probably wouldn't use these data in this way--pretend it is a standard curve or something like that)

input_data <- data_frame(Sepal.Width = c(3,4,5)) # this just creates some sample input data
predict(Sepal_lm, newdata = input_data) # here, we query the linear model, Sepal_lm, created above with the input data
```

Now, repeat this code to determine and graph the correlation between sepal length and petal length in virginica. How does it compare to the correlation between sepal length and sepal width?


**Test 4**:  Is there a difference in mean petal length among any of the species?

Null hypothesis: The mean petal lengths among the species are not different from one another

Alternative hypothesis:  There is a significant difference in the mean petal lengths between at least one pair of species

```{r}
# To test for a significant difference between the means of multiple (>2) groups, perform an ANOVA test
iris_aov <- aov(Petal.Length ~ Species, data = iris)
summary(iris_aov)
```
The highly significant p-value for the F-statistic indicates that there is at least one pair of species with a significant difference.  Which pairs(s)?  To find out, perform a Tukey's HSD posthoc test
```{r}
TukeyHSD(iris_aov)
```
All pairwise combinations of means are significantly different!

```{r}
# power analysis
library(pwr)
library(lsr)
```

These libraries load functions that are useful for analysis of effect sizes and power.  

Cohens D returns a unitless measure of effect size, where < 0.5 is generally considered low, 0.5-0.8 is considered moderate, and > 0.8 is considered high.
```{r}
versicolor <- iris %>% filter(Species == "versicolor")
cohensD(virginica$Sepal.Length, versicolor$Sepal.Length)
```

The power test, pwr.t2n.test takes the following inputs: 
  pwr.t2n.test(n1 = NULL, n2 = NULL, d = NULL, sig.level = 0.05, power = NULL) where 
    *n1 and n2* are the sample sizes of the two samples to be compared 
    *d* is the effect size
    *sig.level* is the significance level (i.e. the threshold below which you are willing to rejecct the null hypothesis)
    *power* is a measure of sensitivity--the higher it is, the less likely you are to inappropriately accept the null hypthesis
  The function must be NULL for exactly one of these parameters and it will solve for the missing parameter
  
```{r}
pwr.t2n.test(n1 = 25, n2 = 25, d = 1.12, sig.level = 0.05) # d is the effect size
pwr.t2n.test(n1 = 25, d = 1.12, sig.level = 0.05, power = 0.9)

# for chi squared effect sizes, calculate w = sqrt(chi-sq value/n)
# VirgSeto chi-sq value is 78 and n is 100, so sqrt(78/100) = 0.88
pwr.chisq.test(w = 0.88, N = 25, df = 1, sig.level = 0.05) 
```

